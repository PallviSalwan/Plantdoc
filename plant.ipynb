{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "191771f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8126f875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/vipoooool/new-plant-diseases-dataset\n",
      "License(s): copyright-authors\n",
      "Downloading new-plant-diseases-dataset.zip to /home/437b/Plantdiseasedetection\n",
      "100%|█████████████████████████████████████▉| 2.69G/2.70G [00:02<00:00, 1.44GB/s]\n",
      "100%|██████████████████████████████████████| 2.70G/2.70G [00:02<00:00, 1.43GB/s]\n"
     ]
    }
   ],
   "source": [
    "#!kaggle datasets download -d vipoooool/new-plant-diseases-dataset\n",
    "#download dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab11ffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"new-plant-diseases-dataset.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"data/raw/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75a066de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "475648bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4e36fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"data/train\"\n",
    "valid_dir = \"data/valid\"\n",
    "test_dir  = \"data/test\"\n",
    "\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=valid_transform)\n",
    "test_data  = datasets.ImageFolder(test_dir,  transform=valid_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238f5706",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=32, shuffle=False)\n",
    "test_loader  = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b818eca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(train_data.classes)\n",
    "num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae9938f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15a81f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False   # Freeze all layers first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c37ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1521d38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "767287ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "246ba650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, valid_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in valid_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_loader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06f590a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Python: /home/437b/.venv/bin/python\n",
      "Requirement already satisfied: numpy in /home/437b/.venv/lib/python3.12/site-packages (2.3.5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "\n",
    "print(\"Using Python:\", sys.executable)\n",
    "\n",
    "# Install numpy into THIS exact Python environment\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"numpy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a74b6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3]\n",
      "Train Loss: 0.5302 | Train Acc: 90.81%\n",
      "Valid Loss: 0.1881 | Valid Acc: 96.07%\n",
      "--------------------------------------------------\n",
      "Epoch [2/3]\n",
      "Train Loss: 0.1586 | Train Acc: 96.29%\n",
      "Valid Loss: 0.1294 | Valid Acc: 97.17%\n",
      "--------------------------------------------------\n",
      "Epoch [3/3]\n",
      "Train Loss: 0.1150 | Train Acc: 96.92%\n",
      "Valid Loss: 0.1013 | Valid Acc: 97.31%\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = 3   # Stage 1: only 3 epochs (quick warm-up)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = validate(model, valid_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Valid Loss: {val_loss:.4f} | Valid Acc: {val_acc:.2f}%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8eeaf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy OK: 2.3.5\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"NumPy OK:\", np.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "908186a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTEBOOK PYTHON = /home/437b/.venv/bin/python\n",
      "NumPy import test: /home/437b/.venv/lib/python3.12/site-packages/numpy/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"NOTEBOOK PYTHON =\", sys.executable)\n",
    "\n",
    "import numpy as np\n",
    "print(\"NumPy import test:\", np.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c6c3605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.9.1\n",
      "Uninstalling torch-2.9.1:\n",
      "  Successfully uninstalled torch-2.9.1\n",
      "Found existing installation: torchvision 0.24.1\n",
      "Uninstalling torchvision-0.24.1:\n",
      "  Successfully uninstalled torchvision-0.24.1\n",
      "\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip uninstall -y torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3d2fe629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/437b/.venv/lib/python3.12/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/437b/.venv/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in /home/437b/.venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/437b/.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/437b/.venv/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m  \u001b[33m0:00:05\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/437b/.venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /home/437b/.venv/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.93)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/437b/.venv/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/437b/.venv/lib/python3.12/site-packages (from torchvision) (2.3.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/437b/.venv/lib/python3.12/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/437b/.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.5.1\n",
      "\u001b[2K    Uninstalling triton-3.5.1:\n",
      "\u001b[2K      Successfully uninstalled triton-3.5.1\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/15\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0[0m \u001b[32m 0/15\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.8.90━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.8.90:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.8.90━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.27.5━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.27.5:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.27.5━━━━━━━━\u001b[0m \u001b[32m 1/15\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.8.93[0m \u001b[32m 3/15\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.8.93:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93━\u001b[0m \u001b[32m 3/15\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.9.90━\u001b[0m \u001b[32m 4/15\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.9.90:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.9.90━━━\u001b[0m \u001b[32m 4/15\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/15\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.3.83━━\u001b[0m \u001b[32m 5/15\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.3.83:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/15\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83━━━━\u001b[0m \u001b[32m 5/15\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90m \u001b[32m 6/15\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/15\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90[0m \u001b[32m 7/15\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/15\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93[0m \u001b[32m 7/15\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/15\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93━\u001b[0m \u001b[32m 7/15\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu120m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/15\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90[0m \u001b[32m 8/15\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/15\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90━\u001b[0m \u001b[32m 8/15\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.8.4.1━━\u001b[0m \u001b[32m 9/15\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.8.4.1:0m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1━━━━\u001b[0m \u001b[32m 9/15\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.3.90[0m \u001b[32m10/15\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.3.90:m━━━━━━━━━━━━━\u001b[0m \u001b[32m10/15\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90━\u001b[0m \u001b[32m10/15\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.10.2.21━━\u001b[0m \u001b[32m11/15\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.10.2.21:0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21━━━━\u001b[0m \u001b[32m11/15\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [torchvision]\u001b[0m [torchvision]-cu12]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a09474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date 4.12,25 unfreeze deeper layers\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layer4\" in name or \"layer3\" in name:  \n",
    "        param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b4f9f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=1e-4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34c67d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3]\n",
      "Train Loss: 0.0361 | Train Acc: 98.81%\n",
      "Valid Loss: 0.0170 | Valid Acc: 99.44%\n",
      "------------------------------------------------\n",
      "Epoch [2/3]\n",
      "Train Loss: 0.0143 | Train Acc: 99.54%\n",
      "Valid Loss: 0.0131 | Valid Acc: 99.60%\n",
      "------------------------------------------------\n",
      "Epoch [3/3]\n",
      "Train Loss: 0.0114 | Train Acc: 99.64%\n",
      "Valid Loss: 0.0075 | Valid Acc: 99.78%\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "epochs = 3  # Stage-2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = validate(model, valid_loader, criterion, device)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Valid Loss: {val_loss:.4f} | Valid Acc: {val_acc:.2f}%\")\n",
    "    print(\"------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "304ed801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: models/plantdoctor_resnet50_stage2.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "model_path = \"models/plantdoctor_resnet50_stage2.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"Model saved to:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a892453e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=38, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca80bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4a59b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "# We'll store activations and gradients here\n",
    "gradcam_activations = {}\n",
    "gradcam_gradients = {}\n",
    "\n",
    "# 1. Hook functions\n",
    "def save_activation(module, input, output):\n",
    "    gradcam_activations[\"value\"] = output.detach()\n",
    "\n",
    "def save_gradient(module, grad_input, grad_output):\n",
    "    # grad_output is a tuple; we want the gradient wrt the output feature maps\n",
    "    gradcam_gradients[\"value\"] = grad_output[0].detach()\n",
    "\n",
    "# 2. Register hooks on the last conv block (layer4)\n",
    "target_layer = model.layer4  # This is the last feature block in ResNet50\n",
    "forward_handle = target_layer.register_forward_hook(save_activation)\n",
    "backward_handle = target_layer.register_full_backward_hook(save_gradient)\n",
    "# If register_full_backward_hook doesn't exist in your PyTorch version,\n",
    "# use: target_layer.register_backward_hook(save_gradient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98ccc5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gradcam_heatmap(model, image_tensor, class_idx=None):\n",
    "    \"\"\"\n",
    "    image_tensor: 1 x 3 x H x W tensor (already normalized & on device)\n",
    "    class_idx: optional, index of target class. If None, uses predicted class.\n",
    "    \"\"\"\n",
    "    model.zero_grad()\n",
    "    gradcam_activations.clear()\n",
    "    gradcam_gradients.clear()\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(image_tensor)  # shape: [1, num_classes]\n",
    "    \n",
    "    if class_idx is None:\n",
    "        class_idx = output.argmax(dim=1).item()\n",
    "    \n",
    "    # Create one-hot for the target class\n",
    "    one_hot = torch.zeros_like(output)\n",
    "    one_hot[0, class_idx] = 1.0\n",
    "    \n",
    "    # Backward pass for that class\n",
    "    output.backward(gradient=one_hot, retain_graph=True)\n",
    "    \n",
    "    # Get stored activations and gradients\n",
    "    activations = gradcam_activations[\"value\"]      # [1, C, H, W]\n",
    "    gradients = gradcam_gradients[\"value\"]          # [1, C, H, W]\n",
    "    \n",
    "    # Global average pooling over gradients -> weights\n",
    "    weights = gradients.mean(dim=(2, 3), keepdim=True)  # [1, C, 1, 1]\n",
    "    \n",
    "    # Weighted sum of activations\n",
    "    cam = (weights * activations).sum(dim=1, keepdim=True)  # [1, 1, H, W]\n",
    "    \n",
    "    # ReLU\n",
    "    cam = F.relu(cam)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    cam = cam - cam.min()\n",
    "    if cam.max() > 0:\n",
    "        cam = cam / cam.max()\n",
    "    \n",
    "    # Resize to 224x224 (or input size)\n",
    "    cam = F.interpolate(cam, size=(224, 224), mode=\"bilinear\", align_corners=False)\n",
    "    \n",
    "    # Convert to numpy\n",
    "    heatmap = cam.squeeze().cpu().numpy()  # H x W (0..1)\n",
    "    return heatmap, class_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99861818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse normalization to get back to [0,1] image for plotting\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "    std=[1/0.229, 1/0.224, 1/0.225]\n",
    ")\n",
    "\n",
    "def tensor_to_numpy_image(tensor):\n",
    "    \"\"\"\n",
    "    tensor: 3 x H x W (normalized)\n",
    "    returns: H x W x 3 image in [0,1]\n",
    "    \"\"\"\n",
    "    img = inv_normalize(tensor.cpu())\n",
    "    img = torch.clamp(img, 0, 1)    # keep in [0,1]\n",
    "    img = img.permute(1, 2, 0).numpy()  # HWC\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b060f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_severity(heatmap, threshold=0.5):\n",
    "    \"\"\"\n",
    "    heatmap: 2D numpy array (0..1) from Grad-CAM\n",
    "    threshold: value above which pixels count as 'infected'\n",
    "    returns: severity_percent, level_string\n",
    "    \"\"\"\n",
    "    # Binary mask of 'hot' regions\n",
    "    infected_mask = heatmap >= threshold\n",
    "\n",
    "    infected_pixels = infected_mask.sum()\n",
    "    total_pixels = heatmap.size\n",
    "\n",
    "    if total_pixels == 0:\n",
    "        return 0.0, \"Unknown\"\n",
    "\n",
    "    severity_percent = (infected_pixels / total_pixels) * 100.0\n",
    "\n",
    "    # Simple severity levels (you can tune thresholds)\n",
    "    if severity_percent < 10:\n",
    "        level = \"Mild\"\n",
    "    elif severity_percent < 30:\n",
    "        level = \"Moderate\"\n",
    "    else:\n",
    "        level = \"Severe\"\n",
    "\n",
    "    return severity_percent, level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43810bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
